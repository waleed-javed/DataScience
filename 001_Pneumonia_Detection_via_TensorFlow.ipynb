{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "001_Pneumonia  Detection via TensorFlow.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOxOdpmz4wcCC2juMf6goN0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waleed-javed/DataScience/blob/main/001_Pneumonia_Detection_via_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzwV9-z5SUG0"
      },
      "source": [
        "## Insatanciating KAGGLE\n",
        "Before Starting we need to setup the kaggle for accessing datasets directly from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJf9Afoa6o5O"
      },
      "source": [
        "#installing Kaggle\n",
        "!pip -q install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuYRsgpESoQd"
      },
      "source": [
        "#upload your JSON-API-Key from kaggle to Drive!\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ieDv91eT3NC"
      },
      "source": [
        "#make a Kaggle directory and copy the APi.Json\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "#check Sucessful,OUTPUT_Required => Kaggle.json\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng7ejcV9VG-4"
      },
      "source": [
        "#After copying you need to enable persmissons for the file to act!\n",
        "!chmod 600 ~/.kaggle/kaggle.json "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebOrpX2NUTKl"
      },
      "source": [
        "'''\n",
        "To list all data sets accessible to you -type\n",
        "Uncomment below code to check '''\n",
        "#!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjVfYwdhWcI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e96f34-cc9c-41f4-92f1-e880e4b509ce"
      },
      "source": [
        "#downloading data from kaggle \n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading chest-xray-pneumonia.zip to /content\n",
            "100% 2.29G/2.29G [00:20<00:00, 23.7MB/s]\n",
            "100% 2.29G/2.29G [00:20<00:00, 119MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg62C5A-Wx1E"
      },
      "source": [
        "!unzip chest-xray-pneumonia.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gKwmxWwsWTB"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tZ3hepvuZsD"
      },
      "source": [
        "### Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNrVYYQ1YbFu"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model, Sequential\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyblJK7l2GTC"
      },
      "source": [
        "### Configrations for Assembling the Model\n",
        "- Assembling so that we get the Categorical output "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okdx3_A9uQdo"
      },
      "source": [
        "#VGG16 net has input dims of 224x224\n",
        "IMAGE_SIZE=[224,224]\n",
        "#defining Train and test path\n",
        "TRAIN_PATH='chest_xray/train'\n",
        "VALIDATION_PATH='chest_xray/test'"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKLa1ju3voN_"
      },
      "source": [
        "vgg16= VGG16(include_top=False, weights='imagenet', input_shape=IMAGE_SIZE+[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKMzKINqwY1N"
      },
      "source": [
        "#Disabling Re-Trainign of all layers because we are working as transfer learning\n",
        "for layer in vgg16.layers:\n",
        "  layer.trainable=False\n",
        "\n",
        "#Useful for getting classes from folder\n",
        "#FOLDERS = glob('/chest_xray/train/*')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp0C-yBgx0kq"
      },
      "source": [
        "#Flasstening the last CUSTOM layer\n",
        "lastLayer= Flatten()(vgg16.output)\n",
        "#prediction Layer\n",
        "prediction= Dense(2, activation='softmax')(lastLayer)\n",
        "#making the model\n",
        "Clf_Model= Model( inputs = vgg16.input, outputs = prediction )\n",
        "#time to check the model summary\n",
        "Clf_Model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3L-DHNt9kWU"
      },
      "source": [
        "### Model Development and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG58sVKX1i-X"
      },
      "source": [
        "Train_data_Gen= ImageDataGenerator(\n",
        "    rescale=1./255, #rescale the images by fractions of 1/255 (Max of Pixel Value)\n",
        "    shear_range=0.2, #0-20% image shear\n",
        "    zoom_range=0.2, #0-20% zooming of images\n",
        "    horizontal_flip=True) #flip the images so that we dont get overfitting"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up9uqpd73Ngj"
      },
      "source": [
        "#Scaling the testing data for consistency in model\n",
        "Test_data_Gen=ImageDataGenerator(rescale= 1./255)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "griBcAzj34nw",
        "outputId": "fefbe5d0-7f2f-4eac-87c2-aa2fbb8e3742"
      },
      "source": [
        "Model_Training_Data= Train_data_Gen.flow_from_directory(directory=TRAIN_PATH,\n",
        "                                                            target_size=IMAGE_SIZE,\n",
        "                                                            batch_size=32,\n",
        "                                                            class_mode='categorical')\n",
        "Model_Testing_Data= Test_data_Gen.flow_from_directory(directory=VALIDATION_PATH,\n",
        "                                                      target_size=IMAGE_SIZE,\n",
        "                                                      batch_size=32,\n",
        "                                                      class_mode='categorical')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0uD9zEiBFX9"
      },
      "source": [
        "#Model Compilation\n",
        "Clf_Model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oGIxvDB5BoV",
        "outputId": "ffb2e6a1-23f9-4769-d511-798f07e6f250"
      },
      "source": [
        "#next step is to compile the model and start Training\n",
        "Trained_Model = Clf_Model.fit_generator(Model_Training_Data,\n",
        "                        validation_data = Model_Testing_Data,\n",
        "                        steps_per_epoch= 50,#len(Model_Training_Data),\n",
        "                        validation_steps = 50,#len(Model_Testing_Data),\n",
        "                        epochs=1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9425 WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "50/50 [==============================] - 1133s 23s/step - loss: 0.1393 - accuracy: 0.9425 - val_loss: 0.3086 - val_accuracy: 0.9054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDwLsJQQ_rqs"
      },
      "source": [
        "from tensorflow.keras.models import save_model,load_model\n",
        "save_model(Trained_Model, 'VGG16_Model_Transfer_Trained_Categorical.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mJVkREh9a7F"
      },
      "source": [
        "### Plotting Model Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV0VEp3_9Nog"
      },
      "source": [
        "fig,ax= plt.subplots(2,1, sharey=True)\n",
        "\n",
        "ax[0].plot(Trained_Model.history['loss'],label='Training Loss')\n",
        "ax[0].plot(Trained_Model.history['val_loss'], label='Validation Loss')\n",
        "\n",
        "ax[1].plot(Trained_Model.history['accuracy'],label='Accuracy')\n",
        "ax[1].plot(Trained_Model.history['val_loss'],label='Accuracy Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyATzlB1_RZy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}